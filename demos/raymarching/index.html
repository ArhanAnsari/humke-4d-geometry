<!DOCTYPE html>
<html>
<head>
    <title>2D Cartesian Shader</title>
    <link rel="icon", href="favicon.png" />
    <link rel="stylesheet" type="text/css" href="normalize.css" />
</head>
<body>
    <section id="viewer"></section>
    <script id="fragmentShader" type="x-shader/x-fragment">
        // From: http://jamie-wong.com/2016/07/15/ray-marching-signed-distance-functions/
        const int MAX_MARCHING_STEPS = 255;
        const float MIN_DIST = 0.0;
        const float MAX_DIST = 100.0;
        const float EPSILON = 0.0001;

        uniform float iTime;
        uniform vec2 iResolution;
        uniform vec2 iMouse;

        /* 
            CSG Functions
            */
        float intersectSDF(float distA, float distB) {
            return max(distA, distB);
        }

        float unionSDF(float distA, float distB) {
            return min(distA, distB);
        }

        float differenceSDF(float distA, float distB) {
            return max(distA, -distB);
        }

        /**
         * Signed distance function for a cube centered at the origin
         * with width = height = length = 2.0
         */
        float cubeSDF(vec3 p) {
            // If d.x < 0, then -1 < p.x < 1, and same logic applies to p.y, p.z
            // So if all components of d are negative, then p is inside the unit cube
            p.y += iMouse.y * 4.0 - 2.0;
            vec3 d = abs(p) - vec3(10.0, 0.01, 10.0);
            
            // Assuming p is inside the cube, how far is it from the surface?
            // Result will be negative or zero.
            float insideDistance = min(max(d.x, max(d.y, d.z)), 0.0);
            
            // Assuming p is outside the cube, how far is it from the surface?
            // Result will be positive or zero.
            float outsideDistance = length(max(d, 0.0));
            
            return insideDistance + outsideDistance;
        }


        /**
         * Signed distance function for a sphere centered at the origin with radius 1.0;
         */
        float sphereSDF(vec3 p) {
            return length(p) - 1.0;
        }

        /**
         * Signed distance function describing the scene.
         * 
         * Absolute value of the return value indicates the distance to the surface.
         * Sign indicates whether the point is inside or outside the surface,
         * negative indicating inside.
         */
        float sceneSDF(vec3 samplePoint) {
            float sphere = sphereSDF(samplePoint);
            float cube = cubeSDF(samplePoint);
            return intersectSDF(sphere,cube);
        }

        /**
         * Return the shortest distance from the eyepoint to the scene surface along
         * the marching direction. If no part of the surface is found between start and end,
         * return end.
         * 
         * eye: the eye point, acting as the origin of the ray
         * marchingDirection: the normalized direction to march in
         * start: the starting distance away from the eye
         * end: the max distance away from the ey to march before giving up
         */
        float shortestDistanceToSurface(vec3 eye, vec3 marchingDirection, float start, float end) {
            float depth = start;
            for (int i = 0; i < MAX_MARCHING_STEPS; i++) {
                float dist = sceneSDF(eye + depth * marchingDirection);
                if (dist < EPSILON) {
                    return depth;
                }
                depth += dist;
                if (depth >= end) {
                    return end;
                }
            }
            return end;
        }
                    

        /**
         * Return the normalized direction to march in from the eye point for a single pixel.
         * 
         * fieldOfView: vertical field of view in degrees
         * size: resolution of the output image
         * fragCoord: the x,y coordinate of the pixel in the output image
         */
        vec3 rayDirection(float fieldOfView, vec2 size, vec2 fragCoord) {
            vec2 xy = fragCoord - size / 2.0;
            float z = size.y / tan(radians(fieldOfView) / 2.0);
            return normalize(vec3(xy, -z));
        }

        /**
         * Using the gradient of the SDF, estimate the normal on the surface at point p.
         */
        vec3 estimateNormal(vec3 p) {
            return normalize(vec3(
                sceneSDF(vec3(p.x + EPSILON, p.y, p.z)) - sceneSDF(vec3(p.x - EPSILON, p.y, p.z)),
                sceneSDF(vec3(p.x, p.y + EPSILON, p.z)) - sceneSDF(vec3(p.x, p.y - EPSILON, p.z)),
                sceneSDF(vec3(p.x, p.y, p.z  + EPSILON)) - sceneSDF(vec3(p.x, p.y, p.z - EPSILON))
            ));
        }

        /**
         * Lighting contribution of a single point light source via Phong illumination.
         * 
         * The vec3 returned is the RGB color of the light's contribution.
         *
         * k_a: Ambient color
         * k_d: Diffuse color
         * k_s: Specular color
         * alpha: Shininess coefficient
         * p: position of point being lit
         * eye: the position of the camera
         * lightPos: the position of the light
         * lightIntensity: color/intensity of the light
         *
         * See https://en.wikipedia.org/wiki/Phong_reflection_model#Description
         */
        vec3 phongContribForLight(vec3 k_d, vec3 k_s, float alpha, vec3 p, vec3 eye,
                                  vec3 lightPos, vec3 lightIntensity) {
            vec3 N = estimateNormal(p);
            vec3 L = normalize(lightPos - p);
            vec3 V = normalize(eye - p);
            vec3 R = normalize(reflect(-L, N));
            
            float dotLN = dot(L, N);
            float dotRV = dot(R, V);
            
            if (dotLN < 0.0) {
                // Light not visible from this point on the surface
                return vec3(0.0, 0.0, 0.0);
            } 
            
            if (dotRV < 0.0) {
                // Light reflection in opposite direction as viewer, apply only diffuse
                // component
                return lightIntensity * (k_d * dotLN);
            }
            return lightIntensity * (k_d * dotLN + k_s * pow(dotRV, alpha));
        }

        /**
         * Lighting via Phong illumination.
         * 
         * The vec3 returned is the RGB color of that point after lighting is applied.
         * k_a: Ambient color
         * k_d: Diffuse color
         * k_s: Specular color
         * alpha: Shininess coefficient
         * p: position of point being lit
         * eye: the position of the camera
         *
         * See https://en.wikipedia.org/wiki/Phong_reflection_model#Description
         */
        vec3 phongIllumination(vec3 k_a, vec3 k_d, vec3 k_s, float alpha, vec3 p, vec3 eye) {
            const vec3 ambientLight = 0.5 * vec3(1.0, 1.0, 1.0);
            vec3 color = ambientLight * k_a;
            
            vec3 light1Pos = vec3(4.0 * sin(iTime),
                                  2.0,
                                  4.0 * cos(iTime));
            vec3 light1Intensity = vec3(0.4, 0.4, 0.4);
            
            color += phongContribForLight(k_d, k_s, alpha, p, eye,
                                          light1Pos,
                                          light1Intensity);
            
            vec3 light2Pos = vec3(2.0 * sin(0.37 * iTime),
                                  2.0 * cos(0.37 * iTime),
                                  2.0);
            vec3 light2Intensity = vec3(0.4, 0.4, 0.4);
            
            color += phongContribForLight(k_d, k_s, alpha, p, eye,
                                          light2Pos,
                                          light2Intensity);    
            return color;
        }

        /**
         * Return a transform matrix that will transform a ray from view space
         * to world coordinates, given the eye point, the camera target, and an up vector.
         *
         * This assumes that the center of the camera is aligned with the negative z axis in
         * view space when calculating the ray marching direction. See rayDirection.
         */
        mat4 viewMatrixF(vec3 eye, vec3 center, vec3 up) {
            // Based on gluLookAt man page
            vec3 f = normalize(center - eye);
            vec3 s = normalize(cross(f, up));
            vec3 u = cross(s, f);
            return mat4(
                vec4(s, 0.0),
                vec4(u, 0.0),
                vec4(-f, 0.0),
                vec4(0.0, 0.0, 0.0, 1)
            );
        }

        void main( )
        {
            vec2 fragCoord = gl_FragCoord.xy;
            vec3 viewDir = rayDirection(45.0, iResolution.xy, fragCoord);
            vec3 eye = vec3(8.0, 5.0, 7.0);
            
            mat4 viewToWorld = viewMatrixF(eye, vec3(0.0, 0.0, 0.0), vec3(0.0, 1.0, 0.0));
            
            vec3 worldDir = (viewToWorld * vec4(viewDir, 0.0)).xyz;
            
            float dist = shortestDistanceToSurface(eye, worldDir, MIN_DIST, MAX_DIST);
            
            if (dist > MAX_DIST - EPSILON) {
                // Didn't hit anything
                gl_FragColor = vec4(0.0, 0.0, 0.0,1.0);
                return;
            }
            
            // The closest point on the surface to the eyepoint along the view ray
            vec3 p = eye + dist * worldDir;
            
            vec3 K_a = vec3(0.2, 0.2, 0.2);
            vec3 K_d = vec3(0.7, 0.2, 0.2);
            vec3 K_s = vec3(1.0, 1.0, 1.0);
            float shininess = 10.0;
            
            vec3 color = phongIllumination(K_a, K_d, K_s, shininess, p, eye);
            
            gl_FragColor = vec4(color, 1.0);
        }
    </script>
    <script id="vertexShader" type="x-shader/x-vertex">
            varying vec4 vertexPosition;
            void main() {
                vertexPosition = modelMatrix * vec4(position,1.0);

                gl_Position = projectionMatrix *
                              modelViewMatrix *
                              vec4(position,1.0); 
            }   
    </script>
    <script src="three.min.js"></script>
    <script type="text/javascript">
        var container, scene, camera, renderer;
        var width = window.innerWidth, height = window.innerHeight;
        var graphWidth, graphHeight;

        init();
        animate();
        function getMousePos(canvas, evt) {
            var rect = canvas.getBoundingClientRect();
            return {
              x: evt.clientX - rect.left,
              y: evt.clientY - rect.top
            };
          }

 
        function init() {
            scene = new THREE.Scene();
            scene.background = new THREE.Color(0xffffff);

            var viewAngle = 75, aspect = width / height, near = 1, far = 1000;
            camera = new THREE.PerspectiveCamera(viewAngle, aspect, near, far);
            camera.position.set(0, 0, 0);

            renderer = new THREE.WebGLRenderer();
            renderer.setSize(width, height);
            renderer.setPixelRatio(window.devicePixelRatio);

            container = document.querySelector("#viewer");
            container.appendChild(renderer.domElement);

            var graph = RayMarchedMesh();
            graph.position.z = -15+ 0.1;
            scene.add(graph);

            var size = 20, divisions = 20, colorCenterLine = 0x444444, colorGrid = 0xd0d0d0;
            var grid = new THREE.GridHelper(size, divisions, colorCenterLine, colorGrid);
            grid.rotation.x = Math.PI/2;
            grid.position.z = -15;
            scene.add(grid);

            var g1 = grid.clone();
           
            g1.position.x += 10;
            g1.position.y -= 10;


            var g2 = grid.clone();
            
            g2.position.x -= 10;
            g2.position.y += 10;

            graphHeight = 700;
            graphWidth = 1600;

            container.addEventListener('mousemove', function(evt) {
                var mousePos = getMousePos(renderer.domElement, evt);
                uniforms.iMouse.value.x = mousePos.x / renderer.domElement.width;
                uniforms.iMouse.value.y = mousePos.y / renderer.domElement.height;

            })

            update();
            window.addEventListener('resize', update, false);
        }

        function update() {
            renderer.setSize(window.innerWidth, window.innerHeight);
            uniforms.iTime.value += 0.1;
            uniforms.iResolution.value.x = graphWidth;
            uniforms.iResolution.value.y = graphHeight;

            
        }

        function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
        }

        function RayMarchedMesh() {

            var geometry = new THREE.PlaneBufferGeometry(20, 20);
            uniforms = {
                'iTime': { type: "f", value: 0 },
                'iResolution': {type: "v2", value: new THREE.Vector2(graphWidth, graphHeight)},
                'iMouse': {type: "v2", value: new THREE.Vector2(0, 0)}
            };
            var material = new THREE.ShaderMaterial({
                uniforms: uniforms,
                fragmentShader: document.querySelector("#fragmentShader").textContent,
                vertexShader: document.querySelector("#vertexShader").textContent
            });
            var graph = new THREE.Mesh(geometry, material);
            graph.position.z = -15;

            return graph;
        }
    </script>
</body>
</html>